<!DOCTYPE html>
<html lang="">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta name="renderer" content="webkit"/>
    <meta name="force-rendering" content="webkit"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <meta name="baidu-site-verification" content="code-8gGOibEXMj" />
    <meta name="google-site-verification" content="r3Cw4aIKBFXcYVnB8J-bxaQozYY6BHsoE3q5soJN3Po" />
    <script>if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode)) window.location.href="https://support.dmeng.net/upgrade-your-browser.html?referrer="+encodeURIComponent(window.location.href); </script>
    
    
        <link rel="shortcut icon" href="/images/avatar.jpg">
    
     
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.13.1/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/vuetify@2.2.30/dist/vuetify.min.css" rel="stylesheet">
    
<link rel="stylesheet" href="/css/main.css">

    
    







    
    
    
        <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        
            load: ['[tex]/mhchem'],
        
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        
            packages: {'[+]': ['mhchem']},
        
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>
          

    
    
    
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
            <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
            <script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>
        
    

    
    
    <title>
        
            Transform与目标跟踪 | CV home
        
    </title>
    
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="app">
        <v-app>
            <v-content id="page">
                <v-container fluid>
                    <v-row>
                        <v-col cols="2" class="d-none d-md-block">
                            <div id="sidebar" class="float-right">
    <a href="/" rel="home">
        <v-avatar size=96>
            <img id="logo" src="/images/avatar.jpg">     
        </v-avatar> 
    </a>
    <v-divider></v-divider>
    <div class="mini-menu">
        <v-btn icon href="/">
            <v-icon>home</v-icon>
        </v-btn>
        <v-btn icon href="/categories/">
            <v-icon>folder</v-icon>
        </v-btn>
        <v-btn icon href="/tags/">
            <v-icon>bookmark</v-icon>
        </v-btn>
        <v-btn icon @click="SetNightMode">
            <v-icon>{{ nightMode }}</v-icon>
        </v-btn>
    </div>
    <v-list id="main-menu" class="font-weight-bold" flat>
        
            
            <v-list-item href="/archives/" link>
            <v-list-item-icon><v-icon>archive</v-icon></v-list-item-icon>
            <v-list-item-content>
                归档
            </v-list-item-content>
            </v-list-item>
        
            
            <v-list-item href="https://space.bilibili.com/5567932/article" link>
            <v-list-item-icon><v-icon>rss_feed</v-icon></v-list-item-icon>
            <v-list-item-content>
                b站专栏
            </v-list-item-content>
            </v-list-item>
        
    </v-list>
    <v-divider></v-divider>
    
        <div class="post-toc">
            <a href="/2021/04/23/tracking/33-transform-tracking/" class="toc-header">文章目录</a>
            <div class="toc-content">
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Transformer-Tracking"><span class="toc-number">1.</span> <span class="toc-text">Transformer Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%9C%BA"><span class="toc-number">1.1.</span> <span class="toc-text">动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">结构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Transformer-Meets-Tracker-Exploiting-Temporal-Context-for-Robust-Visual-Tracking"><span class="toc-number">2.</span> <span class="toc-text">Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%9C%BA-1"><span class="toc-number">2.1.</span> <span class="toc-text">动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-1"><span class="toc-number">2.2.</span> <span class="toc-text">结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%9F%E8%B8%AA%E6%A1%86%E6%9E%B6"><span class="toc-number">2.2.1.</span> <span class="toc-text">跟踪框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.2.2.</span> <span class="toc-text">缺点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Learning-Spatio-Temporal-Transformer-for-Visual-Tracking"><span class="toc-number">3.</span> <span class="toc-text">Learning Spatio-Temporal Transformer for Visual Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%9C%BA-2"><span class="toc-number">3.1.</span> <span class="toc-text">动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-2"><span class="toc-number">3.2.</span> <span class="toc-text">结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Baseline-spatial-only"><span class="toc-number">3.2.1.</span> <span class="toc-text">Baseline (spatial-only)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spatio-Temporal-Transformer-Tracking"><span class="toc-number">3.2.2.</span> <span class="toc-text">Spatio-Temporal Transformer Tracking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E6%96%87%E7%BB%93%E6%9E%84%E4%B8%8EDETR%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">3.2.3.</span> <span class="toc-text">本文结构与DETR的区别</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Target-Transformed-Regression-for-Accurate-Tracking"><span class="toc-number">4.</span> <span class="toc-text">Target Transformed Regression for Accurate Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%9C%BA-3"><span class="toc-number">4.1.</span> <span class="toc-text">动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-3"><span class="toc-number">4.2.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="toc-number">4.3.</span> <span class="toc-text">消融实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%A5%E5%85%85"><span class="toc-number">4.4.</span> <span class="toc-text">补充</span></a></li></ol></li></ol>
            </div>
        </div>
    

    <div id="footer">
        <div class="footer-social">
            
                
                <v-btn icon href="mailto:zjphust@gmail.com" target="_blank">
                    <v-icon>fas fa-envelope</v-icon>
                </v-btn>
            
                
                <v-btn icon href="https://github.com/kongbia" target="_blank">
                    <v-icon>fab fa-github</v-icon>
                </v-btn>
            
        </div>
        <v-divider></v-divider>
        <div class="footer-content">
            
                <span id="busuanzi_container_site_uv" style="display: none;"> 
                    总访客量 <span id="busuanzi_value_site_uv"></span>
                </span>
                <br>
            
            <span>Theme: <a target="_blank" rel="noopener" href="https://github.com/kb1000fx/hexo-theme-insulin">Insulin</a></span><br>
            <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span><br>
            <span>
                &copy; 2021 - 2021 
                zjp
            </span>
        </div>
    </div>
</div>

                        </v-col>
                        <v-col cols="12" md="10">
                            <v-row>
  <v-col cols="12" md="8" align-self="end">
    <div id="site-header">
      <div id="site-title">
        <a href="/" rel="home">CV home</a>
      </div>
      <div id="site-description"></div>
      <div id="mobile-menu" class="d-block d-md-none">
        <v-text-field label="请输入关键字" data-src="search.xml" v-model="searchHeaderValue" prepend-inner-icon="search" clearable clear-icon="clear" @keydown.enter="EnterSearch(searchHeaderValue,true)"></v-text-field>
        <div class="mobile-mini-menu">
          <v-btn icon href="/">
              <v-icon>home</v-icon>
          </v-btn>
          <v-btn icon href="/categories/">
              <v-icon>folder</v-icon>
          </v-btn>
          <v-btn icon href="/tags/">
              <v-icon>bookmark</v-icon>
          </v-btn>
          <v-btn icon @click="SetNightMode">
              <v-icon>{{ nightMode }}</v-icon>
          </v-btn>
          
            
            <v-btn icon href="/archives/">
              <v-icon>archive</v-icon>
            </v-btn>
          
            
            <v-btn icon href="https://space.bilibili.com/5567932/article">
              <v-icon>rss_feed</v-icon>
            </v-btn>
          
        </div>
      </div>    
    </div>
  </v-col>  
  <v-col cols="4" align-self="end" class="d-none d-md-block">
    <v-col align-self="end">
      <v-text-field label="请输入关键字" data-src="search.xml" v-model="searchHeaderValue" prepend-icon="search" clearable clear-icon="clear" @keydown.enter="EnterSearch(searchHeaderValue,true)"></v-text-field>
    </v-col> 
  </v-col>
</v-row>

                            <v-card class="elevation-2 post-card">
    
    
        <div class="post-header">
  <a class="post-header-title font-weight-medium" href="/2021/04/23/tracking/33-transform-tracking/">Transform与目标跟踪</a>
  <div class="post-header-meta">   
    <span>
      <v-icon color="">event</v-icon>
      发布于:&nbsp;2021-04-23
    </span>
    <span>
      <v-icon color="">event_available</v-icon>
      更新于:&nbsp;2021-04-28
    </span>
    <span>
      <v-icon color="">folder</v-icon>
      分类于:&nbsp;<a class="category-link" href="/categories/tracking/">目标跟踪</a>
    </span>
    
    <span>
      <v-icon color="">visibility</v-icon>
      阅读次数:&nbsp;<span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
    </span>
    
  </div>
</div>

    
    
    
    
    <div class="post-content typo">
        <p>Transform在视觉领域遍地开花，终于目标跟踪也没能逃过。并行的长距离依赖（空间和时间皆可）对于目标跟踪似乎有着天然的优势，本篇笔记简要概述今年CVPR2021关于Transform在目标跟踪中的应用，主要介绍动机和结构，细节和实验部分以后有空再补充。</p>
<span id="more"></span>

<p>论文列表：</p>
<ul>
<li>Transformer Tracking</li>
<li>Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking</li>
<li>Learning Spatio-Temporal Transformer for Visual Tracking</li>
<li>Target Transformed Regression for Accurate Tracking</li>
</ul>
<h1 id="Transformer-Tracking"><a href="#Transformer-Tracking" class="headerlink" title="Transformer Tracking"></a>Transformer Tracking</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.15436">论文</a><br><a target="_blank" rel="noopener" href="https://github.com/chenxin-dlut/TransT">代码</a><br><a target="_blank" rel="noopener" href="http://naotu.baidu.com/file/0348e011f8d04a784134e3329a328076?token=53a180e3aa5251ab">代码框架解析</a></p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>跟踪中常用的correlation存在问题：<br>是一个局部线性匹配过程，没有利用全局上下文，容易陷入局部最优；<br>得到的相似图丢失一定程度的语义信息，导致对目标边界预测不准。</p>
<p>利用transform的attention有效融合模板特征和ROI特征，相比correlation能产生更多的语义特征。作者提出了基于self-attention的ego-context augment module (ECA)和基于cross-attention的cross-feature augment module (CFA)<br><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/1.png" style="zoom:80%;" /></p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>重复N=4次fusion layer最后再接一个CFA<br><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/2.png"></p>
<center>整体跟踪框架</center>

<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/3.png" style="zoom:80%;" />

<center>ECA和CFA结构</center>

<p>transform工作过程</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/4.png" style="zoom:80%;" />

<ul>
<li>n=1 self search 没有来自模板的信息，因此会看到所有目标，而self template关注模板的关键信息（蚂蚁上的红点）；cross search和template同时具有目标和搜索的特征，因此可以更关注重要信息；</li>
<li>n=2 每一个attention输入都同时包含目标和搜索特征，self search对相似物的响应被抑制了，而cross search此时非常确信其预测。template的注意力此时开始关注目标边界；</li>
<li>n=3 进一步强化，模板特征成为包含大量目标边界信息的信息库，而搜索区域特征保留了目标的空间信息；</li>
<li>n=4 模板的分布变得混乱，这可能是因为，在目标确定之后，模板分支的特征不再需要保留模板本身的信息，而是存储了大量目标的边界信息，成为一个为回归服务的特征库。</li>
</ul>
<hr>
<h1 id="Transformer-Meets-Tracker-Exploiting-Temporal-Context-for-Robust-Visual-Tracking"><a href="#Transformer-Meets-Tracker-Exploiting-Temporal-Context-for-Robust-Visual-Tracking" class="headerlink" title="Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"></a>Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.11681">论文</a><br><a target="_blank" rel="noopener" href="https://github.com/594422814/TransformerTrack">代码</a></p>
<h2 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h2><p>现有的跟踪器常常忽略连续帧之间的 temporal contexts</p>
<ol>
<li><p>单帧独立检测方法： 对时域信息的利用只有运动先验（余弦窗）</p>
</li>
<li><p>模型更新方法：视频帧是独立的，没有相互推理关系；噪声会污染模型更新</p>
</li>
</ol>
<p>transform中的注意机制，能够建立跨帧的像素对应关系，在时间域内自由传递各种信号。</p>
<p>本文将各个独立的视频帧进行桥接，并通过 transformer 架构来探索它们之间的 temporal contexts，以实现鲁棒的目标跟踪。与经典的 transformer 的结构不同，作者将其编码器和解码器分离成两个平行的分支，并在 Siamese-like 跟踪管道中对其精心设计。</p>
<h2 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h2><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/5.png" style="zoom:80%;" />

<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/10.png" style="zoom:80%;" />

<p>编码器通过基于注意力的特征强化来促进目标模板，有利于高质量的跟踪模型生成；</p>
<p>解码器将之前模板中的跟踪线索传播到当前帧，有利于目标搜索过程。</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/6.png" style="zoom:80%;" />

<p>与经典transform结构的差异：</p>
<ol>
<li>Encoder-decoder Separation. 没有将编码器和解码器级联，而是将编码器和解码器分离为两个分支，以适应Siamese-like跟踪方法；</li>
<li>Block Weight-sharing. 编码器和解码器中的self-attention(图4中的黄色方框)共享权值，将模板和搜索转换到同一特征空间中，便于进一步cross-attention；</li>
<li>Instance Normalization. 将Layer Norm换成Instance Norm；</li>
<li>Slimming Design. 移除FFN，并且使用single-head attention。</li>
</ol>
<p>图4编码器解码器结构细节：</p>
<p>编码器： 输入模板特征 $T \in [N_T, C], N_T=n \times H \times W $, $n$为模板数量；</p>
<p>解码器： 输入搜索特征 $S \in [N_S, C], N_S=H \times W $</p>
<p>高斯Mask     $M \in [N_T, 1] $</p>
<p>Mask Transformation 关注空间注意力，Feature Transformation 关注上下文信息</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/7.png" style="zoom:80%;" />

<h3 id="跟踪框架"><a href="#跟踪框架" class="headerlink" title="跟踪框架"></a>跟踪框架</h3><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/8.png" style="zoom:80%;" />

<ul>
<li><p>Siamese框架将编码器特征crop后和解码器特征做相关；</p>
</li>
<li><p>DCF框架用编码器特征训练Dimp的kernel，作用于解码器特征；</p>
</li>
<li><p>预测框通过probabilistic IoUNet输出；</p>
</li>
<li><p>模板池每5帧更新一次，先入先出。</p>
</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>严重（完全）遮挡，出视野，高计算量</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/9.png" style="zoom:80%;" />

<hr>
<h1 id="Learning-Spatio-Temporal-Transformer-for-Visual-Tracking"><a href="#Learning-Spatio-Temporal-Transformer-for-Visual-Tracking" class="headerlink" title="Learning Spatio-Temporal Transformer for Visual Tracking"></a>Learning Spatio-Temporal Transformer for Visual Tracking</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.17154">论文</a><br><a target="_blank" rel="noopener" href="https://github.com/researchmm/Stark">代码</a></p>
<h2 id="动机-2"><a href="#动机-2" class="headerlink" title="动机"></a>动机</h2><p>卷积只处理空间或时间上的局部关系，不擅长建立长距离的全局依赖关系。因此在面对目标发生较大形变或频繁进出视野时容易失败。另外，当前的方法将空间和时间分离处理，并没有明确建模空间和时间之间的关系。</p>
<p>考虑到transform在建模全局依赖方面的优势，作者利用它整合空间和时间信息进行跟踪，生成判别的时空特征用于目标定位。</p>
<p>编码器对目标对象和搜索区域之间的全局时空特征依赖关系进行建模，而解码器学习一个查询嵌入来预测目标对象的空间位置。该方法将目标跟踪作为一个直接的边框预测问题（角点预测），没有后处理。</p>
<h2 id="结构-2"><a href="#结构-2" class="headerlink" title="结构"></a>结构</h2><h3 id="Baseline-spatial-only"><a href="#Baseline-spatial-only" class="headerlink" title="Baseline (spatial-only)"></a>Baseline (spatial-only)</h3><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/11.png" style="zoom:80%;" />

<p><strong>编码器</strong>输入将模板和搜索特征拉平拼接；</p>
<p><strong>解码器</strong>中query可以注意到模板和搜索区域的所有位置的特征，从而学习鲁棒表示，以进行边框预测；</p>
<p><strong>预测头</strong>将Encoder输出中的搜索特征和decoder输出经过图3的结构，通过概率预测两个角点，最后输出唯一的框，用L1和IOU loss优化。</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/12.png" style="zoom:80%;" />

<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/13.png" style="zoom:80%;" />

<h3 id="Spatio-Temporal-Transformer-Tracking"><a href="#Spatio-Temporal-Transformer-Tracking" class="headerlink" title="Spatio-Temporal Transformer Tracking"></a>Spatio-Temporal Transformer Tracking</h3><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/14.png" style="zoom:80%;" />

<p>相比baseline的改变：三元输入、增加分数预测头、训练&amp;推理策略</p>
<p>训练分为两阶段：第一阶段不训练score head，搜索图像全部包含目标；第二阶段固定其他参数单独训练score head，搜索图像中有一半不包含目标（训练时只要搜索图像包含目标则认为可以更新）；</p>
<p>推理时达到更新间隔且分数大于阈值更新模板</p>
<h3 id="本文结构与DETR的区别"><a href="#本文结构与DETR的区别" class="headerlink" title="本文结构与DETR的区别"></a>本文结构与DETR的区别</h3><ol>
<li>任务不同，检测vs跟踪</li>
<li>输入不同，detr输入整个图像，本文输入三元组，一个search和两个template；</li>
<li>query和训练策略，detr有100个query并且每个都需要匈牙利匹配gt，而本文只有一个query和唯一gt；</li>
<li>预测头不同，detr三层感知器，本文基于角点预测</li>
</ol>
<hr>
<h1 id="Target-Transformed-Regression-for-Accurate-Tracking"><a href="#Target-Transformed-Regression-for-Accurate-Tracking" class="headerlink" title="Target Transformed Regression for Accurate Tracking"></a>Target Transformed Regression for Accurate Tracking</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.00403">论文</a><br><a target="_blank" rel="noopener" href="https://github.com/MCG-NJU/TREG">代码</a></p>
<h2 id="动机-3"><a href="#动机-3" class="headerlink" title="动机"></a>动机</h2><p>如何将目标信息整合到回归分支中，<strong>保留精确的边界信息</strong>并<strong>及时处理各种目标变化</strong>对于跟踪是至关重要的。</p>
<p>dw-corr将整个目标当成滤波器，只有目标的全局信息，面对物体变形时难以准确反映边界；</p>
<p>pix-corr忽略了目标模板中的少量背景会对目标外部区域赋予较大的注意力权重。</p>
<p>作者利用transform的交叉注意力来建模模板和搜索区域的每个元素之间的pair-wise关系，并用其增强原始特征。这种特征表达能够增强目标相关信息，帮助精确定位边界，并由于其局部和密集匹配机制，在一定程度上适应目标变形。</p>
<p>此外，设计了一个简单的在线模板更新机制来选择可靠的模板，提高了对目标外观变化和几何变形的鲁棒性。</p>
<h2 id="结构-3"><a href="#结构-3" class="headerlink" title="结构"></a>结构</h2><p>设计准则：</p>
<ol>
<li>目标集成模块，保留充足的目标信息以生成精确目标边界；</li>
<li>像素级的上下文建模，以增强目标相关的特征和处理形变；</li>
<li>高效的在线机制，以处理连续序列中的外观变化。</li>
</ol>
<p><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/15.png"></p>
<center>TREG整体结构，核心是黄色的target-aware transformer，其余结构参考FCOT</center>

<p><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/16.png"></p>
<center>Online Target-aware Transformer for Regression. (a) Target-aware transformer (b) Online template update mechanism</center>

<p>将搜索特征看成query，目标被编码成key和value，对每一个query，都利用所有key和value为其提供加权聚合响应。</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/17.png" style="zoom:80%;" />

<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/18.png" style="zoom:80%;" />

<p>$x_i$是搜索特征，$t_j$是目标特征，$Ω_k$表示目标模板的所有位置，$k$表示模板池的序号；</p>
<p>$\theta_{x_i}, \phi_{t_j}, \omega_{t_j}$ 分别表示 query, key, value；</p>
<p>注意这里归一化使用1/N而不是softmax。</p>
<blockquote>
<p>The reason lies in that some positions in background and distractors of the search region are expected to have low dependency with target, while Softmax function will amplify this noise influence as the sum of attention weights between the query and all the keys is always 1.</p>
</blockquote>
<p>在线更新模板，构建模板序列，包含3个静态模板和4个动态模板，静态的由第一帧变换增广生成，动态的取每n帧中得分最高的。</p>
<img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/20.png" style="zoom:80%;" />

<h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><img src="https://gitee.com/zjphust/picgo/raw/master/blog/transform-tracking/19.png" style="zoom:80%;" />

<p>图4展示物体在序列发生了变化，本文的transform增强了目标包括头部和脚在内的边界。</p>
<p>表1 TAT-Cls表示将transform用于分类，效果稍微下降，因为pixel-to-pixel的匹配方法往往忽略了目标的整体信息，不适合区分相似的对象。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>本文的结构和CVPR2021另外一篇文章也有些类似，即Graph Attention Tracking，可以参考我在b站的<a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv8692025">笔记</a>。作者将模板和搜索特征的每个位置看成节点，使用图注意力构建局部密集的匹配关系用于加强原始特征。实现方式也和transform的交叉注意力类似，可以说是殊途同归。</p>

    </div>
    <!--文末结束语-->
    
        <div style="text-align:center;color: #ccc;font-size:24px;"> --- 本文结束 <i class="fas fa-heart"></i> The End --- </div>
    
    <!--页脚广告-->
    
    <v-divider></v-divider>
    
    <div class="post-nav">             
        
            <div class="post-nav-button float-left">
                <v-icon>chevron_left</v-icon>
                <a class="font-weight-bold text-left" href="/2021/04/24/tracking/1-siamrcnn/">
                    Siam R-CNN: Visual Tracking by Re-Detection
                </a>
            </div>
              
        
    </div>
</v-card>



    <v-card class="comment-card elevation-2">
        <v-tabs v-model="commentTab"  id="comment-tabs" active-class="active-comment-tab">
            
                <v-tab><span id="comment-tab-0">gitalk</span></v-tab>
            
        </v-tabs>
        <v-tabs-items v-model="commentTab" id="tabs-content" data=eyJ1c2UiOlsiZ2l0YWxrIl0sImdpdGFsa19jbGllbnRfaWQiOiI2OTQ1MTJjNTYxZTdkNjQyMTM5ZiIsImdpdGFsa19jbGllbnRfc2VjcmV0IjoiMjE2OTI5MTRkYWI2YWJhOGI5ZTZjZDUyZTY2ZWFkY2ExMDIyNjZlYiIsImdpdGFsa19yZXBvIjoia29uZ2JpYS5naXRodWIuaW8iLCJnaXRhbGtfb3duZXIiOiJrb25nYmlhIiwiZ2l0YWxrX3NpZF90eXBlIjpudWxsLCJnaXRhbGtfZGlzdHJhY3Rpb25GcmVlTW9kZSI6dHJ1ZSwiZGlzcXVzX3Nob3J0bmFtZSI6bnVsbCwibGl2ZXJlX2RhdGFfdWlkIjpudWxsLCJ2YWxpbmVfbGVhbmNsb3VkX2FwcF9pZCI6bnVsbCwidmFsaW5lX2xlYW5jbG91ZF9hcHBfa2V5IjpudWxsLCJ2YWxpbmVfb3B0aW9uIjpudWxsLCJjaGFuZ3lhbl9hcHBfaWQiOm51bGwsImNoYW5neWFuX2FwcF9rZXkiOm51bGwsImNoYW5neWFuX3NpZF90eXBlIjpudWxsfQ== >
            
                <v-tab-item eager=true>
                    
                        <div id="gitalk-container"></div>
                    
                </v-tab-item>
            
        </v-tabs-items>
    </v-card>

        
                            <div id="mobile-footer" class="d-block d-md-none">
                                <v-divider></v-divider>
                                <div id="mobile-footer-content">
                                    <span>Theme: <a target="_blank" rel="noopener" href="https://github.com/kb1000fx/hexo-theme-insulin">Insulin</a> &nbsp; Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span><br>
                                    <span> &copy; 2021 - 2021 zjp</span>
                                </div>
                            </div>                   
                        </v-col>                                            
                    </v-row>
                </v-container>
            </v-content>
        </v-app>
    </div>
    
<script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script>
<script src="https://cdn.jsdelivr.net/npm/vuetify@2.2.30"></script>
<script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/js-base64@3.5.2/base64.min.js"></script>

<script src="/js/main.js"></script>




    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




    <script src="https://cdn.jsdelivr.net/npm/mermaid@8.4.8/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({
        startOnLoad: true,
        theme: "default"
    });</script>





</body>
</html>