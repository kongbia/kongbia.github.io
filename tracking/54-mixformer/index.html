<!DOCTYPE html>
<html lang="">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta name="renderer" content="webkit"/>
    <meta name="force-rendering" content="webkit"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <meta name="baidu-site-verification" content="code-8gGOibEXMj" />
    <meta name="baidu-site-verification" content="code-Toh8kQYN7N" />
    <meta name="google-site-verification" content="r3Cw4aIKBFXcYVnB8J-bxaQozYY6BHsoE3q5soJN3Po" />
    <meta name="msvalidate.01" content="C5E4D0D01152A883DDA407CDCE62E1DA" />
    <meta name='description' content='A personal blog that shares computer vision papers'>
    <script>if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode)) window.location.href="https://support.dmeng.net/upgrade-your-browser.html?referrer="+encodeURIComponent(window.location.href); </script>
    
    
        <link rel="shortcut icon" href="/images/avatar.jpg">
    
     
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.13.1/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/vuetify@2.2.30/dist/vuetify.min.css" rel="stylesheet">
    
<link rel="stylesheet" href="/css/main.css">

    
    







    
    
          

    
    
    
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
            <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
            <script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>
        
    

    
    
    <title>
        
            MixFormer End-to-End Tracking with Iterative Mixed Attention | CV home
        
    </title>
    
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="app">
        <v-app>
            <v-content id="page">
                <v-container fluid>
                    <v-row>
                        <v-col cols="2" class="d-none d-md-block">
                            <div id="sidebar" class="float-right">
    <a href="/" rel="home">
        <v-avatar size=96>
            <img id="logo" src="/images/avatar.jpg">     
        </v-avatar> 
    </a>
    <v-divider></v-divider>
    <div class="mini-menu">
        <v-btn icon href="/">
            <v-icon>home</v-icon>
        </v-btn>
        <v-btn icon href="/categories/">
            <v-icon>folder</v-icon>
        </v-btn>
        <v-btn icon href="/tags/">
            <v-icon>bookmark</v-icon>
        </v-btn>
        <v-btn icon @click="SetNightMode">
            <v-icon>{{ nightMode }}</v-icon>
        </v-btn>
    </div>
    <v-list id="main-menu" class="font-weight-bold" flat>
        
            
            <v-list-item href="/archives/" link>
            <v-list-item-icon><v-icon>archive</v-icon></v-list-item-icon>
            <v-list-item-content>
                归档
            </v-list-item-content>
            </v-list-item>
        
            
            <v-list-item href="https://space.bilibili.com/5567932/article" link>
            <v-list-item-icon><v-icon>rss_feed</v-icon></v-list-item-icon>
            <v-list-item-content>
                b站专栏
            </v-list-item-content>
            </v-list-item>
        
    </v-list>
    <v-divider></v-divider>
    
        <div class="post-toc">
            <a href="/tracking/54-mixformer/" class="toc-header">文章目录</a>
            <div class="toc-content">
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Motivation"><span class="toc-number">1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method"><span class="toc-number">2.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Mixed-Attention-Module-MAM"><span class="toc-number">2.1.</span> <span class="toc-text">Mixed Attention Module (MAM)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Localization-Head"><span class="toc-number">2.2.</span> <span class="toc-text">Localization Head</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Template-Online-Update"><span class="toc-number">2.3.</span> <span class="toc-text">Template Online Update</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-and-Inference"><span class="toc-number">2.4.</span> <span class="toc-text">Training and Inference</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Experiments"><span class="toc-number">3.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SOTA%E6%AF%94%E8%BE%83"><span class="toc-number">3.1.</span> <span class="toc-text">SOTA比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%A9%B6%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.2.</span> <span class="toc-text">探究实验</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-2-3-8-%E7%BB%9F%E4%B8%80%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%92%8C%E8%9E%8D%E5%90%88%E7%9A%84MAM%E6%AF%94%E5%85%88%E6%8F%90%E7%89%B9%E5%BE%81SAM%E5%86%8D%E8%9E%8D%E5%90%88CAM%E8%A6%81%E5%A5%BD%EF%BC%8C%E5%9B%A0%E4%B8%BA%E8%80%A6%E5%90%88%E7%9A%84%E6%96%B9%E5%BC%8F%E5%8F%AF%E4%BB%A5%E4%BA%92%E7%9B%B8%E4%BF%83%E8%BF%9B%E3%80%82"><span class="toc-number">4.</span> <span class="toc-text">1 #2 #3 #8 统一特征提取和融合的MAM比先提特征SAM再融合CAM要好，因为耦合的方式可以互相促进。</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-5-6-7-8-MAM%E7%9A%84%E6%95%B0%E9%87%8F%E8%B6%8A%E5%A4%9A%E8%B6%8A%E5%A5%BD%EF%BC%8C%E5%9B%A0%E4%B8%BA%E8%BF%99%E6%A0%B7%E5%8F%AF%E4%BB%A5%E8%8E%B7%E5%BE%97%E6%9B%B4extensive-%E7%9A%84%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%92%8C%E5%88%86%E5%B1%82%E8%9E%8D%E5%90%88%E3%80%82"><span class="toc-number">5.</span> <span class="toc-text">4 #5 #6 #7 #8 MAM的数量越多越好，因为这样可以获得更extensive 的目标感知特征提取和分层融合。</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-9-corner-head%E6%AF%94query-head%E6%95%88%E6%9E%9C%E6%9B%B4%E5%A5%BD"><span class="toc-number">6.</span> <span class="toc-text">8 #9 corner head比query head效果更好</span></a></li></ol>
            </div>
        </div>
    

    <div id="footer">
        <div class="footer-social">
            
                
                <v-btn icon href="mailto:zjphust@gmail.com" target="_blank">
                    <v-icon>fas fa-envelope</v-icon>
                </v-btn>
            
                
                <v-btn icon href="https://github.com/kongbia" target="_blank">
                    <v-icon>fab fa-github</v-icon>
                </v-btn>
            
        </div>
        <v-divider></v-divider>
        <div class="footer-content">
            
                <span id="busuanzi_container_site_uv" style="display: none;"> 
                    总访客量 <span id="busuanzi_value_site_uv"></span>
                </span>
                <br>
            
            <span>Theme: <a target="_blank" rel="noopener" href="https://github.com/kb1000fx/hexo-theme-insulin">Insulin</a></span><br>
            <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span><br>
            <span>
                &copy; 2020 - 2022 
                zjp
            </span>
        </div>
    </div>
</div>

                        </v-col>
                        <v-col cols="12" md="10">
                            <v-row>
  <v-col cols="12" md="8" align-self="end">
    <div id="site-header">
      <div id="site-title">
        <a href="/" rel="home">CV home</a>
      </div>
      <div id="site-description">A personal blog that shares computer vision papers</div>
      <div id="mobile-menu" class="d-block d-md-none">
        <v-text-field label="请输入关键字" data-src="search.xml" v-model="searchHeaderValue" prepend-inner-icon="search" clearable clear-icon="clear" @keydown.enter="EnterSearch(searchHeaderValue,true)"></v-text-field>
        <div class="mobile-mini-menu">
          <v-btn icon href="/">
              <v-icon>home</v-icon>
          </v-btn>
          <v-btn icon href="/categories/">
              <v-icon>folder</v-icon>
          </v-btn>
          <v-btn icon href="/tags/">
              <v-icon>bookmark</v-icon>
          </v-btn>
          <v-btn icon @click="SetNightMode">
              <v-icon>{{ nightMode }}</v-icon>
          </v-btn>
          
            
            <v-btn icon href="/archives/">
              <v-icon>archive</v-icon>
            </v-btn>
          
            
            <v-btn icon href="https://space.bilibili.com/5567932/article">
              <v-icon>rss_feed</v-icon>
            </v-btn>
          
        </div>
      </div>    
    </div>
  </v-col>  
  <v-col cols="4" align-self="end" class="d-none d-md-block">
    <v-col align-self="end">
      <v-text-field label="请输入关键字" data-src="search.xml" v-model="searchHeaderValue" prepend-icon="search" clearable clear-icon="clear" @keydown.enter="EnterSearch(searchHeaderValue,true)"></v-text-field>
    </v-col> 
  </v-col>
</v-row>

                            <v-card class="elevation-2 post-card">
    
    
        <div class="post-header">
  <a class="post-header-title font-weight-medium" href="/tracking/54-mixformer/">MixFormer End-to-End Tracking with Iterative Mixed Attention</a>
  <div class="post-header-meta">   
    <span>
      <v-icon color="">event</v-icon>
      发布于:&nbsp;2022-05-24
    </span>
    <span>
      <v-icon color="">event_available</v-icon>
      更新于:&nbsp;2022-05-31
    </span>
    <span>
      <v-icon color="">folder</v-icon>
      分类于:&nbsp;<a class="category-link" href="/categories/tracking/">目标跟踪</a>
    </span>
    
    <span>
      <v-icon color="">visibility</v-icon>
      阅读次数:&nbsp;<span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
    </span>
    
  </div>
</div>

    
    
    
    
    <div class="post-content typo">
        <p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524172159.png" alt=""></p>
<p>MixFormer: End-to-End Tracking with Iterative Mixed Attention <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.11082">论文</a> <a target="_blank" rel="noopener" href="https://github.com/MCG-NJU/MixFormer">代码</a></p>
<p>核心：用transfrom架构整合特征提取和特征融合</p>
<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524172748.png" alt=""></p>
<p>主流的跟踪框架分三步：特征提取、特征融合、预测头分类回归</p>
<p>其中特征融合是关键，下图展示了不同的融合方法。（摘自 <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1L541127MD?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">【VALSE论文速览-68期】MixFormer:更加简洁的端到端单目标跟踪器</a>）</p>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524172920.png" alt=""></p>
<p>最近的研究使用transformer进行融合，但仍然依赖CNN提取特征，这其中存在一些局限：</p>
<ol>
<li>attention只作用在高层抽象的特征表示空间，忽略了浅层特征；</li>
<li>CNN对通用对象识别进行预训练，可能会忽略用于跟踪的更精细的结构信息；</li>
<li>CNN的表征能力是局部的，缺乏长距离建模的能力</li>
</ol>
<p>解决方案：</p>
<p>提出一个通用的transformer结构同时进行特征提取和特征融合。</p>
<p>具有如下好处:</p>
<ol>
<li>使特征提取更具体到相应的跟踪目标，并捕获更多目标特定的判别特征;</li>
<li>让目标信息更extensive的融合进搜索区域；</li>
<li>结构更加紧凑简洁。</li>
</ol>
<p>主要创新点：</p>
<ul>
<li>提出了 MAM 模块，应用 attnetion 机制同时进行特征提取与信息交互</li>
<li>提出SPM模块进行模板更新</li>
</ul>
<span id="more"></span>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524213439.png" alt=""></p>
<p>网络整体框架如图3所示，包括两部分：模板和搜索图像经过基于mixed attention module(MAM)的backbone进行特征提取和融合，再通过预测头输出结果。backbone部分包含3个stage，每个stage输入特征首先经过patch embedding变成一系列token，然后送入MAM模块提取并融合特征。预测头部分直接将融合后的搜索区域的token输入进行预测。</p>
<h2 id="Mixed-Attention-Module-MAM"><a href="#Mixed-Attention-Module-MAM" class="headerlink" title="Mixed Attention Module (MAM)"></a>Mixed Attention Module (MAM)</h2><p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524220836.png" alt=""></p>
<p>本文的核心模块MAM，目的是同时提取并融合模板和搜索图像的特征，因此设计了dual attention分别用于二者。具体来说，MAM输入模板和搜索特征拼接成的 token序列，首先会将输入分开并reshape 成二维的模板和搜索特征，经过$3\times3$ DW卷积编码局部上下文和线性映射生成q，k，v后，同时进行 self-attention和 cross-attention。</p>
<p>注意MAM 是一个非对称的attention，删去了target-to-search的cross-attention。如图2所示，模板的q只会和模板自己的k，v计算attention（黄色虚线）；而搜索图的q会同时和模板和搜索图的k，v计算attention（蓝色虚线）。用公式表达为：</p>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524222647.png" alt=""></p>
<p>这样做可以使得模板的token在跟踪过程中保持不变，避免被动态的搜索区域影响。为后续引入多个在线模板做铺垫，无需每帧重新计算模板token。</p>
<h2 id="Localization-Head"><a href="#Localization-Head" class="headerlink" title="Localization Head"></a>Localization Head</h2><p>采用类似stark的角点预测模式。作者也额外尝试了类似detr的采用一个query进行预测的方式。均无需后处理。</p>
<h2 id="Template-Online-Update"><a href="#Template-Online-Update" class="headerlink" title="Template Online Update"></a>Template Online Update</h2><p>在线更新模板能够很好的利用时序信息处理一些形变和外观变化，然而低质量的更新模板可能使得结果变差。本文设计了一个score prediction module (SPM)，根据预测置信度得分来选择可靠的在线模板，如图4所示。</p>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524224125.png" alt=""></p>
<p>SPM由两个attention和一个三层的MLP组成，该模块接在backbone最后一个stage后，和预测头是并行的。首先输入一个可学习的score token，与search ROI token计算attention，对搜索图中挖掘的目标信息进行编码。然后将score token与第一帧的模板token做attention，隐式地将挖掘的目标与初始目标进行比较。最后过一个MLP预测出置信度得分，小于0.5判断为不可靠。</p>
<h2 id="Training-and-Inference"><a href="#Training-and-Inference" class="headerlink" title="Training and Inference"></a>Training and Inference</h2><p>作者设计了两种网络架构MixFormer 和 MixFormer-L ，分别基于CVT-21 和 CVT24-W，也就是说可以使用CVT在Imagenet上预训练的权重来初始化backbone（虽然原始的CVT并没有两个输入，计算attention的方式也不一样，但是每个block的参数是一样的）。</p>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524225610.png" alt=""></p>
<p>训练过程分为两步，首先用500个epoch训练backbone和head；最后用40个epoch单独训练SPM，冻结其他部分参数。这个训练流程和stark类似。</p>
<p>推理阶段每隔200帧更新一次模板，选择区间中得分最高的模板替换先前的模板。本文的框架允许输入任意张数的模板，代码实现中只包含两张模板，一张初始模板，一张在线更新模板。</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="SOTA比较"><a href="#SOTA比较" class="headerlink" title="SOTA比较"></a>SOTA比较</h2><p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524234306.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524234318.png" alt=""></p>
<p>SOTA性能就一个字：恐怖！</p>
<h2 id="探究实验"><a href="#探究实验" class="headerlink" title="探究实验"></a>探究实验</h2><p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524234504.png" alt=""></p>
<ul>
<li><h1 id="1-2-3-8-统一特征提取和融合的MAM比先提特征SAM再融合CAM要好，因为耦合的方式可以互相促进。"><a href="#1-2-3-8-统一特征提取和融合的MAM比先提特征SAM再融合CAM要好，因为耦合的方式可以互相促进。" class="headerlink" title="1 #2 #3 #8 统一特征提取和融合的MAM比先提特征SAM再融合CAM要好，因为耦合的方式可以互相促进。"></a>1 #2 #3 #8 统一特征提取和融合的MAM比先提特征SAM再融合CAM要好，因为耦合的方式可以互相促进。</h1></li>
<li><h1 id="4-5-6-7-8-MAM的数量越多越好，因为这样可以获得更extensive-的目标感知特征提取和分层融合。"><a href="#4-5-6-7-8-MAM的数量越多越好，因为这样可以获得更extensive-的目标感知特征提取和分层融合。" class="headerlink" title="4 #5 #6 #7 #8 MAM的数量越多越好，因为这样可以获得更extensive 的目标感知特征提取和分层融合。"></a>4 #5 #6 #7 #8 MAM的数量越多越好，因为这样可以获得更extensive 的目标感知特征提取和分层融合。</h1></li>
<li><h1 id="8-9-corner-head比query-head效果更好"><a href="#8-9-corner-head比query-head效果更好" class="headerlink" title="8 #9 corner head比query head效果更好"></a>8 #9 corner head比query head效果更好</h1></li>
</ul>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524235111.png" alt=""></p>
<ul>
<li>使用非堆成结构效果略有下降，但是速度提升了</li>
<li>从固定间隔中随机采样更新模板效果变差了，加上预测得分后才能提升效果</li>
<li>pretrain的规模越大，对效果也是有提升的。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kongbia/picgo/master/blog/54-MixFormer/20220524235732.png" alt=""></p>
<p>Attention可视化</p>
<ul>
<li>背景中的干扰物逐层受到抑制</li>
<li>在线模板更适应外观变化并有助于区分目标</li>
<li>多个模板的前景可以通过交叉注意力来增强</li>
<li>某个位置倾向于与周围的局部块相互作用。</li>
</ul>

    </div>
    <!--文末结束语-->
    
        <div style="text-align:center;color: #ccc;font-size:24px;"> --- 本文结束 <i class="fas fa-heart"></i> The End --- </div>
    
    <!--页脚广告-->
    
    <v-divider></v-divider>
    
    <div class="post-nav">             
              
          
            <div class="post-nav-button float-right">
                <a class="font-weight-bold text-right" href="/tracking/53-SBT/">      
                    SBT Correlation-Aware Deep Tracking
                </a>
                <v-icon>chevron_right</v-icon>
            </div>
        
    </div>
</v-card>



    <v-card class="comment-card elevation-2">
        <v-tabs v-model="commentTab"  id="comment-tabs" active-class="active-comment-tab">
            
                <v-tab><span id="comment-tab-0">gitalk</span></v-tab>
            
        </v-tabs>
        <v-tabs-items v-model="commentTab" id="tabs-content" data=eyJ1c2UiOlsiZ2l0YWxrIl0sImdpdGFsa19jbGllbnRfaWQiOiI2OTQ1MTJjNTYxZTdkNjQyMTM5ZiIsImdpdGFsa19jbGllbnRfc2VjcmV0IjoiMjE2OTI5MTRkYWI2YWJhOGI5ZTZjZDUyZTY2ZWFkY2ExMDIyNjZlYiIsImdpdGFsa19yZXBvIjoia29uZ2JpYS5naXRodWIuaW8iLCJnaXRhbGtfb3duZXIiOiJrb25nYmlhIiwiZ2l0YWxrX3NpZF90eXBlIjpudWxsLCJnaXRhbGtfZGlzdHJhY3Rpb25GcmVlTW9kZSI6dHJ1ZSwiZGlzcXVzX3Nob3J0bmFtZSI6bnVsbCwibGl2ZXJlX2RhdGFfdWlkIjpudWxsLCJ2YWxpbmVfbGVhbmNsb3VkX2FwcF9pZCI6bnVsbCwidmFsaW5lX2xlYW5jbG91ZF9hcHBfa2V5IjpudWxsLCJ2YWxpbmVfb3B0aW9uIjpudWxsLCJjaGFuZ3lhbl9hcHBfaWQiOm51bGwsImNoYW5neWFuX2FwcF9rZXkiOm51bGwsImNoYW5neWFuX3NpZF90eXBlIjpudWxsfQ== >
            
                <v-tab-item eager=true>
                    
                        <div id="gitalk-container"></div>
                    
                </v-tab-item>
            
        </v-tabs-items>
    </v-card>

        
                            <div id="mobile-footer" class="d-block d-md-none">
                                <v-divider></v-divider>
                                <div id="mobile-footer-content">
                                    <span>Theme: <a target="_blank" rel="noopener" href="https://github.com/kb1000fx/hexo-theme-insulin">Insulin</a> &nbsp; Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span><br>
                                    <span> &copy; 2020 - 2022 zjp</span>
                                </div>
                            </div>                   
                        </v-col>                                            
                    </v-row>
                </v-container>
            </v-content>
        </v-app>
    </div>
    
<script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script>
<script src="https://cdn.jsdelivr.net/npm/vuetify@2.2.30"></script>
<script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/js-base64@3.5.2/base64.min.js"></script>

<script src="/js/main.js"></script>




    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




    <script src="https://cdn.jsdelivr.net/npm/mermaid@8.4.8/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({
        startOnLoad: true,
        theme: "default"
    });</script>




    
        <script data-ad-client="ca-" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    


</body>
</html>